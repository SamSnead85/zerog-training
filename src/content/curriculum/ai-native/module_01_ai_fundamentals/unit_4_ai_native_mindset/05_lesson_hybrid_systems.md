# Lesson 4.5: Building Hybrid Human-AI Systems

> **Duration**: 45 minutes | **Type**: Practical/Design
> **Unit**: 4 - The AI-Native Mindset

---

## üìö Reading Material

### The Hybrid Imperative

The most effective AI systems aren't fully automated‚Äîthey're **hybrid**, combining AI capabilities with human judgment. This lesson covers how to design these systems.

### The Human-AI Collaboration Spectrum

```
Full Automation ‚Üê‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí Full Human

     1              2              3              4
     ‚îÇ              ‚îÇ              ‚îÇ              ‚îÇ
AI Only      AI Lead +       Human Lead +      Human Only
            Human Review     AI Assist
```

Most production systems operate in zones 2 and 3.

### Design Patterns for Human-AI Systems

**Pattern 1: AI Draft, Human Edit**
AI creates initial output; humans refine.

```
Use cases: Content creation, code generation, reports
Flow: AI generates ‚Üí Human reviews ‚Üí Human edits ‚Üí Publish
Benefit: 70% time savings while maintaining quality
```

**Pattern 2: AI Filter, Human Handle**
AI processes routine cases; humans handle exceptions.

```
Use cases: Customer support, document processing
Flow: AI classifies ‚Üí Low-risk auto-resolve ‚Üí High-risk to human
Benefit: Handle 5x volume with same staff
```

**Pattern 3: Human Decide, AI Execute**
Humans make decisions; AI carries them out.

```
Use cases: Campaign management, order processing
Flow: Human configures rules ‚Üí AI monitors/triggers ‚Üí AI executes
Benefit: Scalable execution of human strategy
```

**Pattern 4: AI Suggest, Human Approve**
AI makes recommendations; humans have veto.

```
Use cases: Medical diagnosis, financial advice
Flow: AI analyzes ‚Üí AI suggests ‚Üí Human reviews ‚Üí Human approves/modifies
Benefit: AI scales expertise while maintaining accountability
```

### Designing Effective Handoffs

**Clear Triggers**
```python
handoff_rules = {
    "confidence < 0.7": "human_review",
    "customer_tier == 'enterprise'": "human_review",
    "contains(keywords=['legal', 'lawsuit'])": "human_escalation",
    "sentiment < -0.8": "priority_human"
}
```

**Context Transfer**
Humans need context to work efficiently:
- Original input
- AI's analysis and confidence
- Relevant policy/history
- Suggested action (optional)

**Feedback Loops**
Human actions should improve AI:
- Track human corrections
- Flag disagreements for training data
- Regular model updates

### The Human Experience in AI Systems

**Design for Human Attention**
- Surface what needs attention, hide what doesn't
- Prioritize by urgency and impact
- Provide one-click actions for common decisions

**Avoid Automation Complacency**
- Don't make approval too easy (one-click approve-all)
- Randomly require detailed review (spot checks)
- Show AI confidence prominently
- Highlight uncertainty

**Build Trust Gradually**
- Start with AI-assist, not AI-lead
- Show AI reasoning
- Track and display accuracy
- Let humans calibrate trust

### Metrics for Hybrid Systems

**Automation Rate**: % of cases handled without human
**Escalation Rate**: % of cases needing human review
**Human Time per Case**: Time spent on escalated cases
**Correction Rate**: How often humans change AI output
**Human Override Quality**: Accuracy of human corrections

```python
metrics = {
    "automation_rate": cases_auto_handled / total_cases,
    "escalation_rate": cases_escalated / total_cases,
    "human_time_saved": (baseline_time - actual_human_time) / baseline_time,
    "correction_rate": human_corrections / ai_outputs,
    "quality_after_edit": satisfaction_with_edited / total_edited
}
```

### Case Study: Medical Imaging AI

**System Design**:
1. AI analyzes radiology images
2. AI flags potential abnormalities with confidence scores
3. Radiologist reviews AI-flagged images (high priority)
4. Radiologist reviews random sample of AI-normal images
5. All diagnoses require radiologist sign-off

**Results**:
- 40% reduction in review time
- 20% more abnormalities caught (AI spots subtle patterns)
- Zero increase in missed diagnoses (human review catches AI errors)
- Radiologist satisfaction high (less tedious work, more interesting cases)

---

## üé¨ Video Script

**[INTRO - Human and AI icons working together]**

The best AI systems aren't fully automated. They're hybrid‚Äîcombining AI's scale with human judgment. Let me show you how to design these.

**[CUT TO: Collaboration spectrum]**

Think of a spectrum. On one end, full automation. On the other, full human. Most production systems live in the middle: AI lead with human review, or human lead with AI assist.

**[CUT TO: Pattern 1 diagram]**

Pattern one: AI draft, human edit. AI creates the first version‚Äîa blog post, code, a report. Humans refine. You save 70% of time while maintaining quality.

**[CUT TO: Pattern 2 diagram]**

Pattern two: AI filter, human handle. AI handles routine cases automatically. Complex ones go to humans. You handle five times the volume with the same team.

**[CUT TO: Pattern 3 diagram]**

Pattern three: human decide, AI execute. Humans set strategy. AI executes at scale. Campaign rules, automated responses‚Äîhuman judgment scales through AI.

**[CUT TO: Pattern 4 diagram]**

Pattern four: AI suggest, human approve. AI analyzes and recommends. Humans review and decide. Critical for high-stakes domains‚Äîmedicine, finance. AI scales expertise while keeping humans accountable.

**[CUT TO: Handoff design elements]**

Handoffs matter. Define clear triggers‚Äîwhen does AI escalate? Transfer context‚Äîgive humans everything they need. Create feedback loops‚Äîhuman corrections improve the AI.

**[CUT TO: Human experience principles]**

Design for human attention. Surface what matters, hide what doesn't. Avoid automation complacency‚Äîmake approval require thought. Build trust gradually.

**[CUT TO: Medical imaging case study]**

Real example: medical imaging AI. AI analyzes radiology scans, flags potential issues, radiologists review flagged images plus random samples. Results: 40% faster, 20% more abnormalities caught, zero increase in missed diagnoses.

**[CUT TO: Speaker on camera]**

The goal isn't to replace humans‚Äîit's to amplify them. AI handles volume and pattern recognition. Humans provide judgment and accountability. Together, they're more capable than either alone.

**[END - Runtime: 6:30]**

---

## üî¨ Interactive Lab: Hybrid System Design

### Objective
Design a complete hybrid human-AI system.

### Part 1: System Architecture (25 minutes)

```python
from enum import Enum
from dataclasses import dataclass
from typing import List, Optional, Dict

class AssignmentTarget(Enum):
    AI_AUTO = "ai_auto"
    AI_SUGGEST_HUMAN_APPROVE = "ai_suggest"
    HUMAN_QUEUE = "human_queue"
    PRIORITY_HUMAN = "priority_human"

@dataclass
class WorkItem:
    id: str
    content: str
    metadata: Dict
    ai_output: Optional[Dict] = None
    human_output: Optional[Dict] = None
    assignment: Optional[AssignmentTarget] = None

class HybridRoutingSystem:
    def __init__(self):
        self.rules = []
        self.queues = {
            AssignmentTarget.AI_AUTO: [],
            AssignmentTarget.AI_SUGGEST_HUMAN_APPROVE: [],
            AssignmentTarget.HUMAN_QUEUE: [],
            AssignmentTarget.PRIORITY_HUMAN: [],
        }
    
    def add_rule(self, condition, target, priority=0):
        """Add routing rule. Higher priority rules checked first."""
        self.rules.append({
            "condition": condition,
            "target": target,
            "priority": priority
        })
        self.rules.sort(key=lambda r: r["priority"], reverse=True)
        return self
    
    def route(self, item: WorkItem) -> AssignmentTarget:
        """Determine routing for a work item."""
        for rule in self.rules:
            if rule["condition"](item):
                item.assignment = rule["target"]
                self.queues[rule["target"]].append(item)
                return rule["target"]
        
        # Default: human queue
        item.assignment = AssignmentTarget.HUMAN_QUEUE
        self.queues[AssignmentTarget.HUMAN_QUEUE].append(item)
        return AssignmentTarget.HUMAN_QUEUE
    
    def get_stats(self):
        total = sum(len(q) for q in self.queues.values())
        return {
            target.value: len(items) / total if total else 0
            for target, items in self.queues.items()
        }

# Build a customer support routing system
support_router = HybridRoutingSystem()

# High priority: escalation keywords
support_router.add_rule(
    condition=lambda item: any(kw in item.content.lower() 
        for kw in ["legal", "lawyer", "sue", "urgent", "emergency"]),
    target=AssignmentTarget.PRIORITY_HUMAN,
    priority=100
)

# Enterprise customers always get human review
support_router.add_rule(
    condition=lambda item: item.metadata.get("customer_tier") == "enterprise",
    target=AssignmentTarget.AI_SUGGEST_HUMAN_APPROVE,
    priority=80
)

# Low confidence AI ‚Üí human queue
support_router.add_rule(
    condition=lambda item: item.ai_output and item.ai_output.get("confidence", 0) < 0.7,
    target=AssignmentTarget.HUMAN_QUEUE,
    priority=50
)

# High confidence + simple question ‚Üí auto-resolve
support_router.add_rule(
    condition=lambda item: (
        item.ai_output and 
        item.ai_output.get("confidence", 0) > 0.9 and
        item.ai_output.get("complexity") == "simple"
    ),
    target=AssignmentTarget.AI_AUTO,
    priority=30
)

# Medium confidence ‚Üí AI suggest, human approve
support_router.add_rule(
    condition=lambda item: item.ai_output and item.ai_output.get("confidence", 0) >= 0.7,
    target=AssignmentTarget.AI_SUGGEST_HUMAN_APPROVE,
    priority=20
)

# Test with sample items
test_items = [
    WorkItem("1", "How do I reset my password?", 
             {"customer_tier": "standard"},
             {"confidence": 0.95, "complexity": "simple"}),
    WorkItem("2", "I'm going to sue you!", 
             {"customer_tier": "standard"}, None),
    WorkItem("3", "Need help with integration", 
             {"customer_tier": "enterprise"},
             {"confidence": 0.85, "complexity": "medium"}),
    WorkItem("4", "What are your pricing plans?",
             {"customer_tier": "standard"},
             {"confidence": 0.6, "complexity": "simple"}),
]

print("Routing Results:")
print("=" * 50)
for item in test_items:
    target = support_router.route(item)
    print(f"\n'{item.content[:40]}...'")
    print(f"  ‚Üí {target.value}")

print(f"\nüìä Distribution: {support_router.get_stats()}")
```

### Part 2: Human Interface Design (20 minutes)

```python
@dataclass
class ReviewContext:
    """Context provided to human reviewer"""
    item: WorkItem
    ai_analysis: Dict
    suggested_response: str
    confidence_score: float
    similar_cases: List[Dict]
    applicable_policies: List[str]
    
    def display(self):
        print("="*60)
        print("HUMAN REVIEW REQUIRED")
        print("="*60)
        
        print(f"\nüìß Customer Message:")
        print(f"   {self.item.content}")
        
        print(f"\nü§ñ AI Analysis:")
        print(f"   Classification: {self.ai_analysis.get('category')}")
        print(f"   Sentiment: {self.ai_analysis.get('sentiment')}")
        print(f"   Confidence: {self.confidence_score:.1%}")
        
        print(f"\nüìù Suggested Response:")
        print(f"   {self.suggested_response}")
        
        print(f"\nüìã Applicable Policies:")
        for policy in self.applicable_policies:
            print(f"   ‚Ä¢ {policy}")
        
        print(f"\nüìö Similar Past Cases:")
        for case in self.similar_cases[:2]:
            print(f"   ‚Ä¢ {case['summary']} (resolved: {case['resolution']})")
        
        print("\n" + "-"*60)
        print("Actions: [A]pprove  [E]dit  [R]eject  [S]calate")

class HumanReviewQueue:
    def __init__(self):
        self.pending = []
        self.completed = []
        self.metrics = {"approved": 0, "edited": 0, "rejected": 0}
    
    def add_for_review(self, context: ReviewContext):
        self.pending.append(context)
    
    def process_next(self):
        if not self.pending:
            print("No items pending review")
            return None
        
        context = self.pending.pop(0)
        context.display()
        
        # Simulate human action (in real system, this would be UI input)
        action = input("\nYour action: ").lower()
        
        if action == 'a':
            self.metrics["approved"] += 1
            result = {"action": "approved", "response": context.suggested_response}
        elif action == 'e':
            self.metrics["edited"] += 1
            new_response = input("Enter edited response: ")
            result = {"action": "edited", "response": new_response}
        elif action == 'r':
            self.metrics["rejected"] += 1
            result = {"action": "rejected", "reason": input("Rejection reason: ")}
        else:
            return self.process_next()  # Invalid input
        
        self.completed.append((context, result))
        return result
    
    def get_correction_rate(self):
        total = self.metrics["approved"] + self.metrics["edited"]
        if total == 0:
            return 0
        return self.metrics["edited"] / total

# Example usage
sample_context = ReviewContext(
    item=WorkItem("5", "I want a refund but it's been over 30 days",
                  {"customer_tier": "standard"}),
    ai_analysis={"category": "refund", "sentiment": "frustrated"},
    suggested_response="I understand you'd like a refund. While our standard policy is 30 days, I'd be happy to make an exception. I've processed your refund, which should appear in 3-5 business days.",
    confidence_score=0.75,
    similar_cases=[
        {"summary": "30-day refund exception", "resolution": "approved"},
        {"summary": "45-day refund request", "resolution": "partial_refund"}
    ],
    applicable_policies=["30-day return policy", "Customer satisfaction exception"]
)

# Display what human reviewer sees
sample_context.display()
```

### Submission
Design a hybrid system for a use case in your organization, including routing rules and human interface.

---

## ‚úÖ Knowledge Check

### Question 1
In the "AI Draft, Human Edit" pattern, what is the main benefit?

A) Complete automation  
B) 70% time savings while maintaining quality  
C) No human involvement  
D) Lower AI costs  

**Correct Answer**: B

**Explanation**: AI drafting followed by human editing typically saves 70% of creation time while allowing humans to refine and ensure quality.

---

### Question 2
What should be included in context transfer for human reviewers?

A) Just the customer message  
B) Only the AI's response  
C) Original input, AI analysis, confidence, relevant policies, and suggested action  
D) The AI model's training data  

**Correct Answer**: C

**Explanation**: Effective context transfer includes everything the human needs: original input, AI's analysis and confidence, relevant policies/history, and the suggested action for quick decision-making.

---

### Question 3
Why should you avoid making AI approval "too easy" (one-click approve-all)?

A) It's bad for user experience  
B) It causes automation complacency where humans rubber-stamp without reviewing  
C) It's more expensive  
D) Regulations prohibit it  

**Correct Answer**: B

**Explanation**: If approval is too easy, humans may develop automation complacency‚Äîapproving without genuine review. Adding friction (spot checks, requiring reading before approve) maintains vigilance.

---

### Question 4
What is the "correction rate" metric?

A) How often the system crashes  
B) How often humans change AI output  
C) How fast corrections are made  
D) How many errors AI makes  

**Correct Answer**: B

**Explanation**: Correction rate measures how often humans modify AI output. High correction rates may indicate the AI needs improvement; low rates suggest the AI is performing well.

---

*Congratulations on completing Unit 4! You now have the AI-Native mindset‚Äîknowing when to use AI, when not to, and how to design effective human-AI systems.*
